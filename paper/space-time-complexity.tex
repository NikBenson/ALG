\section{Mathematische Eigenschaften}
	Wie die meisten Sortieralgorithmen ist Samplesort mathematisch darstellbar.
	Hierbei gibt es viele Perspektiven.
	Im Folgenden ist die Laufzeit- und Speicherkomplexität dargestellt.
	
	\subsection{Speicherkomplexität}
		Samplesort ist ein in-place Sortieralgorithmus.
		Das heißt, es wird kein zusätzlicher Speicher benötigt.\\
		Soweit die Theorie zur Standardvariante.
		Anders ist es beim Super Scalar Sample Sort (sss-Sort). \autocite{sanders-2004} 
		Dieser benötigt einen 2. temporären Array mit n Elementen und damit doppelt so viel Speicher.
		An der Speicherkomplexität ändert sich damit allerdings nichts, diese bleibt bei $\Theta(n)$.
	\subsection{Laufzeitkomplexität}
		Ein häufig verwendetes Maß für die Performanz eines Sortieralgorithmus sind die benötigten vergleiche.
		Diese Differenzierung ist wichtig, da verschiedene Operationen\footnote{Im Regelfall Vergleichsoperationen und Speicherzugriffe}, bei unterschiedlichen Datenmodellen, unterschiedlich gewichtet Zeit, bzw. Prozessoroperationen, benötigen.
		Wenn, wie in \ref{sec:implementation}, lediglich Integer verglichen werden\footnote{In der Regel benötigt diese Operation lediglich so viel Zeit, wie eine Subtraktionsoperation}, so ist die benötigte Zeit vernachlässigbar.
		Allerdings tritt ein Problem mit dem sogenannten Conditional branches, also den bedingten Abzweigungen der Byte~code~instruktionen, auf:
		Werden die Anweisungen in das Register, also den Anweisungscache, des Prozessors geladen, so ist die Wahrscheinlichkeit für jede Abzweigung, also jedes Ergebnis der Vergleichsoperation, bei $n\log{n}$\footnote{Da jedes Element transitiv mit jedem anderen verglichen wird} vergleichen, annähernd $50\%$.
		Damit kann keine Sinnvolle Annahme getroffen werden, welche Instruktionen in das Register geladen werden sollen.
		Wird der falsche Zweig genommen, so muss die Operation wiederholt werden und wenn alle Möglichkeiten geladen werden, wird für jeden Abzweig die Last verdoppelt. \autocite{sanders-2004}\\
		Damit ist es dennoch in unserem Interesse, die Anzahl der vergleiche gering zu halten, außer dieses Problem wird, mit der parallelisierung der Vergleiche, durch sss-Sort umgangen.
		
		\paragraph{Sortierren der Sample}
			Beim Sortieren der Sample werden $C_\textit{smallSort}(s)$ vergleiche benötigt, wobei $C_\textit(n)$ die Funktion der Vergleiche von \textit{smallSort} ist, und $s$ die Größe der Sample.
			Für Quicksort gilt durchschnittlich $C_\textit{smallSort}(n)=n\log{n}$. \autocite{wikipedia-contributors-2022}
			
		\paragraph{Schwellenwertunterschreitung}
			Ist die durchschnittliche Größe eines Buckets kleiner als der Schwellenwertes, also $\frac{n}{s+1}\leq \textit{threshold}$, so gilt erneut $C_\textit{threshold}(n)=n\log{n}$
		
		\paragraph{Verteilen auf Buckets}
			Das verteilen auf die Buckets ist an sich bereits ein Devide-And-Conquer-Algorithmus.
			Seien $s$ die Anzahl der Splitter und $n$ die Anzahl der Elemente, die keine Splitter sind, so lässt sich folgende Rekursionsgleichung\footnote{Auch bekannt als Differenzengleichung} ableiten, vorausgesetzt $s,n\in \{\mathbb{N}\to 2^n\}$:
			\begin{equation}
				C_{s,n}=n+2\cdot C_{\frac{s-1}{2}, \frac{n}{2}}%TODO initial condition
			\end{equation}
