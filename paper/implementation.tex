\section{Implementierung}
	Es gibt viele verschiedene Variationen, Samplesort zu implementieren. Zu viele, um sie hier alle zu nennen.
	Im Folgenden sind die bekanntesten Variationen dargestellt.\\
	Dazu sind zunächst ein paar Grundbegriffe von Nöten:
	\paragraph{Splitter}
		Splitter wurden bereits in der Einleitung erwähnt.
		Dort haben wir uns damit begnügt, diese mit den Pivot Elementen beim Quicksort zu vergleichen.
		Die Konzepte sind dabei sehr ähnlich.\\
		Während Quicksort die Daten mit dem Pivot Element in 2 Sektionen unterteilt, da binär die einfachste Aufteilungsmöglichkeit ist, wenn die Anzahl irrelevant ist, unterteilt Samplesort die Daten mit $n$ Splittern in $n+1$ Buckets.
	\paragraph{Bucket}
		Ein Bucket ist der Bereich zwischen zwei benachbarten Splittern, so wie die beiden Bereiche neben dem größten sowie kleinsten Splitter.\\
		Wenn $\{10, 20, 30\}$ die 3 Splitter sind, dann ergeben sich daraus also die Buckets $\{(-\infty;10],\allowbreak [10;20],\allowbreak [20;30],\allowbreak [30;\infty)\}$.\\
		Wichtig ist dabei, dass Elemente, die den selben Wert, wie ein Splitter haben, entweder in den Bucket links, oder rechts, von jenem, eingeordnet werden können.\\
		Das Ziel ist dabei häufig, die Anzahl der Buckets identisch zur Anzahl der verfügbaren Prozessorkerne zu setzen, damit die Buckets parallel sortiert werden. Dies ist in \ref{sec:multithreading} weiter ausgeführt.

	\subsection{Grundger\"ust}
		Der grundlegende Aufbau ist dabei immer identisch und in \ref{fig:skeletton} beispielhaft dargestellt:
		\lstinputlisting[language=C, caption={Samplesort Implementierung \autocite{benson-2022}}, label=fig:skeletton]{../code/src/samplesort/samplesort.c}
		Zu erkennen sind 3 schritte, denen im folgenden auch jeweils eine Überschrift gewidmet ist:
		\begin{enumerate}
			\item Auswählen von $\textit{bucketsCount}-1$ splittern
			\item Zuordnen der Werte zu den sich daraus ergebenden Buckets
			\item Sortieren der Buckets
		\end{enumerate}
		Diese Phasen lassen sich 1:1 auf den klassischen Quicksort abbilden:
		\begin{enumerate}
			\item Wählen des Pivot Elements
			\item Kleinere Elemente links, größere Elemente rechts des Pivot Elements positionieren
			\item Bereiche links und rechts des Pivot Elements sortieren
		\end{enumerate}
		

	\subsection{Auswahl der Splitter}
		Das Ziel bei der Auswahl der Splitter ist, dass möglichst gleich große Buckets entstehen.
		\lstinputlisting[language=C, caption={Auswahl der Splitter \autocite{benson-2022}}, label=fig:select_splitters]{../code/src/samplesort/select_splitters.c}
		Während der grundlegende Aufbau, wie in \ref{fig:select_splitters} dargestellt, immer der selbe ist, kann die Auswahl der Sample auf 4 verschiedene Arten erfolgen:\footnote{Sortiert von schnellster Laufzeit zu größter Randomisierung} \autocite{berlin-2007}
		\begin{itemize}
			\item \ref{sec:block} Block
			\item \ref{sec:even} Gleichmäßig
			\item \ref{sec:semi-random} Semi-Zufällig
			\item \ref{sec:random} Zufällig
		\end{itemize}
		
		\paragraph{Oversampling}
			Die Sample ist dabei ein ausgewählter Teilbereich der Daten. Der \textit{oversamplingFactor} gibt an, wie wie groß die Sample ist, in der Form $\textit{sampleSize}=\textit{splittersCount}\cdot\textit{oversamplingFactor}$.\\
		
		\paragraph{Verwendung der Sample}
			Die Sample wird sortiert und die Splitter werden gleichmäßig aus der Sample entnommen.
			Dieser Prozess dient dazu, dass die Splitter die Buckets möglichst gleichmäßig unterteilen.

		\subsubsection{Block}
			\label{sec:block}
			\lstinputlisting[language=C, caption={Auswahl der Sample mit dem Block Verfahren \autocite{benson-2022}}, label=fig:select_sample_bloc]{../code/src/samplesort/choose_sample/block.c}
			Hier besteht die Sample aus den ersten Elementen der zu sortierenden Daten.
			Da hier kein zusätzlicher Aufwand betrieben wird, ist diese Variante mit einer Laufzeit von $O(0)$ am schnellsten.
			Allerdings ist hier das Risiko dafür, dass die Buckets entarten, also deutlich unterschiedlich groß werden, das höchste.

		\subsubsection{Gleichmäßig}
			\label{sec:even}
			\lstinputlisting[language=C, caption={Auswahl der Sample in gleichmäßigen Schritten \autocite{benson-2022}}, label=fig:select_sample_even]{../code/src/samplesort/choose_sample/even.c}
			Bei diesem Verfahren werden gleich verteilt Elemente aus den Daten gewählt, in dem jedes $\textit{dataLength}/\textit{sampleLength}$-te Element der Sample hinzugefügt wird.\\
			Mit einer Laufzeit von $O(n)$ ist dieses Verfahren schneller als zufällige Verfahren, da keine zufälligen Zahlen generiert werden müssen.
			Auch werden sowohl bei zufälligen, als auch bei vollständig sortierten Daten, passende Splitter gefunden.
			Allerdings entfällt das Zufallselement, was den Algorithmus anfälliger für bestimmte vorhandene Strukturen macht.
			Das Risiko zu entarten ist allerdings in den meisten Anwendungsfällen nicht relevant.
			Deshalb ist dies die häufigste Implementierung.

		\subsubsection{Semi-Zufällig}
			\label{sec:semi-random}
			\lstinputlisting[language=C, caption={Auswahl der Sample Semi-Zufällig \autocite{benson-2022}}, label=fig:select_sample_semi-random]{../code/src/samplesort/choose_sample/semi_random.c}
			Diese Methode ergänzt die Schrittweite von \ref{sec:even} um einen zufälligen Faktor.
			Entsprechend ähnlich ist die Laufzeit mit $O(n)+O_R$, wobei R die Berechnung einer Zufallszahl ist.
			Auch wenn das Ausmaß der Entartung verringert wird, so ist diese Implementierung für die selben Muster anfällig wie \ref{sec:even} und wenn dieser schlecht funktioniert empfiehlt es sich, \ref{sec:random} zu verwenden.

		\subsubsection{Zufällig}
			\label{sec:random}
			\lstinputlisting[language=C, caption={Auswahl der Sample Zufällig \autocite{benson-2022}}, label=fig:select_sample_random]{../code/src/samplesort/choose_sample/random.c}
			Mit dieser Implementierung wird durch eine vollständig zufällige Auswahl die vollständige Unabhängigkeit von den zu sortierenden Daten gewährleistet.\\
			Im durchschnitt werden so genau die mittleren Splitter, die versucht werden, möglichst genau zu treffen, gefunden.
			 Allerdings, dadurch, dass dies vom Zufall abhängig ist, ist dies, abgesehen vom Oversampling, auch nur im Durchschnitt, der Fall.\\
			 Durch das Oversampling ist die Wahrscheinlichkeit, dass annähernd optimale Splitter ausgewählt werden, vorausgesetzt, es gibt nicht zu viele Duplikate, allerdings ziemlich hoch\\%TODO find maths
			 Auch steigt die Laufzeit auf $O(n\cdot O_R)$.\\
			 
			 \paragraph{Equality buckets}
			 	Gibt es zu viele, nicht einzigartige, Elemente, so wird die Auswahl der optimalen Splitter, nicht nur bei einer zufälligen Wahl, proportional unzuverlässiger.
			 	Hierzu können Equality Buckets genutzt werden.
			 	Dabei bildet jeder Splitter einen eigenen Bucket, der alle Elemente fasst, die einen identischen Wert haben.\\
			 	Desto mehr Duplikate es gibt, desto wahrscheinlicher ist, dass ein solches Duplikat als Splitter gewählt wird.

	\subsection{Zuordnen jeden Wertes zu dem passenden Bucket}
		\lstinputlisting[language=C, caption={Finden des richtigen Buckets \autocite{benson-2022}}, label=fig:place_elements_in_appropriate_bucket]{../code/src/samplesort/place_elements_in_corresponding_bucket.c}
		An der Länge des Beispiels alleine ist zu erkennen, dass dies der aufwändigste schritt ist.
		Dies liegt daran, dass es keinen Algorithmus gibt, der in einer Iteration, alle Splitter richtig positioniert.
		Entsprechend müssen die Daten wiederholt an einem Splitter, analog zum Quicksort, verteilt werden.\\
		In \ref{fig:place_elements_in_appropriate_bucket} wird hier zu ein Rekursiver Ansatz gewählt.
		Es sind aber auch imperative Ansätze denkbar.\\
		Ein wichtiges Detail ist, die in-place Architektur beizubehalten.
		Hierzu werden die Splitter als erstes an die beiden Enden der Daten aufgeteilt, bevor der Bereich dazwischen aufgeteilt wird.
		Daraus ergibt sich, dass von der Mitte der Splitter nach außen gearbeitet wird.\\
		Daraus ergeben sich $n\log_2s$ vergleiche so wie Austausch Operationen, was einer Laufzeitkomplexität von $\Theta(n\log{s})$ entspricht.\footnote{$n$ ist die Anzahl der Elemente und $s$ die Anzahl der Splitter}

	\subsection{Sortieren der Buckets}
		Um den Sortierprozess fertig zu stellen ist es noch notwendig, alle Buckets zu sortieren.
		Zu diesem Zweck gibt es 2 Überkategorien:
		\subsubsection{Original}
			Im Original \autocite{frazer-1970} wird Quicksort verwendet, um die Buckets zu sortieren.
			Der zugrundeliegende Gedanke ist, dass, durch das initiale gleichmäßige verteilen der Elemente, jeder Prozessorkern nun annähernd gleich viele Elemente bearbeiten soll.\\
			Auch wenn im Original Quicksort verwendet wird, so wird dieser Gedanke auch von jeglichem Divide-and-Conquer Algorithmus mit einer durchschnittlichen Laufzeit von annähernd $O(n\log{n})$\footnote{Diese Angabe ist ein Richtwert. Vorausgesetzt es gibt sinnvolle Gründe, wie das verringern von Vergleichen, kann es sinnvoll sein, diese Laufzeitkomplexität auch im größeren Maße zu überschreiten.} umgesetzt. 
		\subsubsection{Rekursiv}
			Dem entgegen steht die rekursive Implementierung.
			Diese ist auch in \ref{fig:skeletton} umgesetzt.\\
			Hier ist der Vorteil der geringen Anzahl an Vergleichen von Samplesort länger gegeben. Als Rekursionsanker dient in der Regel ein Schwellenwert (\textit{Threshold}).
			Überschreitet die durchschnittliche Größe eines Buckets diese Zahl, so wird zu einem alternativen Sortieralgorithmus gewechselt. \\
			Hier bietet sich Insertion Sort an, da dieser für kleine Datenmengen optimal ist. \autocite{geeksforgeeks-2021} 
			In vielen Ausführungen ist hier allerdings auch ein Quicksort zu finden.
			Die Entscheidung sollte von der Größe des Schwellenwerts getrieben sein.
			
