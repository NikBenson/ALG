\section{Implementierung}
	\label{sec:implementation}
	Es gibt viele verschiedene Variationen, Samplesort zu implementieren.
	Um ein viel genutztes Beispiel zu nennen, die Implementierung von \textit{std::sort} der C++ Standardbibliothek. \autocite{unknown-author-2019}
	Diese Implementierung gilt als eine der schnellsten Samplesort Implementierungen, ist allerdings nicht parallelisiert.
	Dem entgegen steht die Implementierung von STAPL, die parallelisierte Standartbibliothek. \autocite{berlin-2007}\\
	Diese Varianten fördern allerdings nicht das Verständnis, weshalb wir uns mit einer eigenen Implementierung auseinandersetzen werden.
	Dazu sind zunächst ein paar Grundbegriffe notwendig:
	\paragraph{Splitter}
		Splitter wurden bereits in der Einleitung erwähnt.
		Dort haben wir uns damit begnügt, diese mit den Pivot Elementen beim Quicksort zu vergleichen.
		Die Konzepte sind dabei sehr ähnlich.\\
		Während Quicksort die Daten mit dem Pivot Element in 2 Sektionen unterteilt, da binär die einfachste Aufteilungsmöglichkeit ist, wenn die Anzahl irrelevant ist, unterteilt Samplesort die Daten mit $n$ Splittern in $n+1$ Buckets.
	\paragraph{Bucket}
		Ein Bucket ist der Bereich zwischen zwei benachbarten Splittern, so wie die beiden Bereiche neben dem größten sowie kleinsten Splitter.
		Dies ist in \ref{fig:buckets-from-splitters} am Beispiel der Splitter 100, 200 \& 300 visuell dargestellt.
		\begin{figure}[h]
			\caption{Buckets für Splitter \autocite{benson-2022}}
			\label{fig:buckets-from-splitters}
			\begin{center}
				\begin{math}
					\begin{matrix}
						 \ldots  & 100 &  \ldots  & 200 &  \ldots  & 300 &  \ldots  \\
						\uparrow &     & \uparrow &     & \uparrow &     & \uparrow \\
					\end{matrix}
				\end{math}
			\end{center}
		\end{figure}\\
		Ein Sonderfall sind dabei Elemente, die den selben Wert wie ein Splitter haben.
		Für sie ist nicht definiert, ob sie in den Bucket links oder rechts des Splitters ein zu ordnen sind.\\
		Das Ziel von Buckets ist dabei häufig, die Anzahl der Buckets identisch zur Anzahl der verfügbaren Prozessorkerne zu setzen, damit die Buckets parallel sortiert werden.
		Dies ist in \ref{sec:multithreading} weiter ausgeführt.

	\subsection{Phasen des Algorithmus}
		Der grundlegende Aufbau ist dabei immer identisch und in \ref{fig:skeletton} beispielhaft dargestellt:
		\lstinputlisting[language=C, caption={Samplesort Implementierung \autocite{benson-2022}}, label=fig:skeletton]{../code/src/samplesort/samplesort.c}
		Zu erkennen sind 3 Phasen, denen im folgenden auch jeweils eine Überschrift gewidmet ist:
		\begin{enumerate}
			\item Auswählen von $\textit{splittersCount}$ Splittern
			\item Zuordnen der Werte zu den sich daraus ergebenden Buckets
			\item Sortieren der Buckets
		\end{enumerate}
		Diese Phasen lassen sich 1:1 auf den klassischen Quicksort abbilden:
		\begin{enumerate}
			\item Wählen des Pivot Elements
			\item Kleinere Elemente links, größere Elemente rechts des Pivot Elements positionieren
			\item Bereiche links und rechts des Pivot Elements sortieren
		\end{enumerate}
		

	\subsection{Auswahl der Splitter}
		Das Ziel bei der Auswahl der Splitter ist, dass möglichst gleich große Buckets entstehen.
		\lstinputlisting[language=C, caption={Auswahl der Splitter \autocite{benson-2022}}, label=fig:select_splitters]{../code/src/samplesort/select_splitters.c}
		Zunächst wird eine Sample, also eine Repräsentative Teilmenge der gesamt Daten, gebildet.
		Diese wird sortiert und die Splitter werden in gleichmäßigen Abständen aus der sortierten Sample entnommen.\\
		\begin{figure}[h]
			\caption{Ermitteln der Splitter aus der sortierten Sample \autocite{benson-2022}}
			\label{fig:splitters-from-sample}
			\begin{center}
				\begin{tabular}{ c c c c c c c c c c c c }
						 1     & 1 & 2 &      3     & 5 & 8 &     13     & 21 & 34 &     55     & {\color{red} 89} & {\color{red} 144} \\
					$\uparrow$ &   &   & $\uparrow$ &   &   & $\uparrow$ &    &    & $\uparrow$ &                  &
				\end{tabular}
			\end{center}
		\end{figure}\\
		Ist die Sample hinreichend repräsentativ, so folgt daraus, dass die resultierenden Splitter die Daten in annähernd identisch große Buckets unterteilt.\\
		Dieser Prozess nennt sich \textbf{Oversampling}.
		Er leitet sich aus dem \qq{Median of 3 Quicksort} ab.
		Es werden mehr Splitter/Pivot Elemente generiert, damit aus ihnen die optimalen ausgewählt werden können (Siehe \ref{fig:splitters-from-sample}).\\
		Die größe der Sample ergibt sich dabei aus der Formel $(\textit{splittersCount}-1)\cdot\textit{oversamplingFactor}+1$.
		Dieses Implementierungsdetail ergibt sich daraus, dass das erste Element jedes Blocks als Splitter genommen wird und lediglich das erste Element des letzten Blocks benötigt wird. (Die Roten Elemente in \ref{fig:splitters-from-sample} sind überflüssig.)
		Dieses Detail ist dennoch wichtig, da viele Vergleiche beim Sortieren der Sample gespart werden.\\
		Die Auswahl der Sample kann dabei auf 4 verschiedene Arten erfolgen:\footnote{Sortiert von schnellster Laufzeit zu größter Randomisierung} \autocite{berlin-2007}

		\subsubsection{Block}
			\label{sec:block}
			\lstinputlisting[language=C, caption={Auswahl der Sample mit dem Block Verfahren \autocite{benson-2022}}, label=fig:select_sample_bloc]{../code/src/samplesort/choose_sample/block.c}
			Hier besteht die Sample aus den ersten/letzten Elementen der zu sortierenden Daten.
			Da hier kein zusätzlicher Aufwand betrieben wird, ist diese Variante mit einer Laufzeit von $O(0)$ am schnellsten.
			Allerdings ist hier das Risiko dafür, dass die Buckets entarten, also deutlich unterschiedlich groß werden, das höchste.
			Diese Variante ist auch beim klassischen Quicksort die üblichste.

		\subsubsection{Gleichmäßig}
			\label{sec:even}
			\lstinputlisting[language=C, caption={Auswahl der Sample in gleichmäßigen Schritten \autocite{benson-2022}}, label=fig:select_sample_even]{../code/src/samplesort/choose_sample/even.c}
			Bei diesem Verfahren werden gleich verteilt Elemente aus den Daten gewählt, in dem jedes $\textit{dataLength}/\textit{sampleLength}$-te Element der Sample hinzugefügt wird.\\
			Mit einer Laufzeit von $O(n)$ ist dieses Verfahren schneller als zufällige Verfahren, da keine zufälligen Zahlen generiert werden müssen.
			Auch werden sowohl bei zufälligen, als auch bei vollständig sortierten Daten, passende Splitter gefunden.
			Allerdings entfällt das Zufalls-Element, was den Algorithmus anfälliger für bestimmte vorhandene Strukturen macht.
			Das Risiko zu entarten ist allerdings in den meisten Anwendungsfällen nicht relevant.
			Deshalb ist dies die häufigste Implementierung.

		\subsubsection{Semi-Zufällig}
			\label{sec:semi-random}
			\lstinputlisting[language=C, caption={Auswahl der Sample Semi-Zufällig \autocite{benson-2022}}, label=fig:select_sample_semi-random]{../code/src/samplesort/choose_sample/semi_random.c}
			Diese Methode ergänzt die Schrittweite von \ref{sec:even} um einen zufälligen Faktor.
			Es wird jedes $r$-te Element genommen, wobei $r$ eine zufällige Ganzzahl kleiner der Schrittweite bei \ref{sec:even} ist.\\
			Entsprechend ähnlich ist die Laufzeit mit $O(n)+O_R$, wobei R die Berechnung einer Zufallszahl ist.
			Auch wenn das Ausmaß der Entartung verringert wird, so ist diese Implementierung für ähnliche Muster anfällig wie \ref{sec:even} und wenn dieser schlecht funktioniert empfiehlt es sich, \ref{sec:random} zu verwenden.

		\subsubsection{Zufällig}
			\label{sec:random}
			\lstinputlisting[language=C, caption={Zufällige Auswahl der Sample \autocite{benson-2022}}, label=fig:select_sample_random]{../code/src/samplesort/choose_sample/random.c}
			Mit dieser Implementierung wird durch eine vollständig zufällige Auswahl die vollständige Unabhängigkeit von den zu sortierenden Daten gewährleistet.\\
			Im Durchschnitt werden so genau die mittleren Splitter, die versucht werden, möglichst genau zu treffen, gefunden.
			Allerdings, dadurch, dass dies vom Zufall abhängig ist, ist dies, abgesehen vom Oversampling, auch nur im Durchschnitt, der Fall.\\
			Durch das Oversampling ist die Wahrscheinlichkeit, dass annähernd optimale Splitter ausgewählt werden, vorausgesetzt, es gibt nicht zu viele Duplikate, allerdings ziemlich hoch.
			Um genau zu sein wird die durchschnittliche Distanz zu den optimalen Splittern durch den \textit{oversamplingFactor} geteilt.\\
			Auch steigt die Laufzeit auf $O(n\cdot O_R)$.\footnote{Zur Veranschaulichung, technisch ist dies immer noch eine Laufzeit von $O(n)$}

			\paragraph{Equality buckets}
				Gibt es viele gleichwertige Elemente müssen viele vermeidbare Vergleiche durchgeführt werden.
				Hier helfen Equality buckets.\\
				Die Wahrscheinlichkeit, dass Elemente, die häufig vorkommen, als Splitter ausgewählt werden, ist am größten.
				Deshalb bilden, bei einer Implementierung mit Equality Buckets, die Splitter jeweils einen eigenen bucket, der nur gleichwertige Elemente fast.
				Daraus resultiert, dass die gleichwertigen Elemente schnell aus dem Weg geräumt werden.\\
				Die Beispiel-Implementierung hat keine Equality Buckets.

	\subsection{Zuordnen jeden Wertes zu dem passenden Bucket}
		\lstinputlisting[language=C, caption={Finden des richtigen Buckets \autocite{benson-2022}}, label=fig:place_elements_in_appropriate_bucket]{../code/src/samplesort/place_elements_in_corresponding_bucket.c}
		Nun gilt es, die Elemente den Buckets zuzuordnen.
		Für einen Array gibt es keine Möglichkeit, dies in einer Iteration zu realisieren.
		Begründet wird dies dadurch, dass die tatsächliche Größe der Buckets noch nicht bekannt ist.\\
		Deshalb wird derselbe Algorithmus wie beim klassischen Quicksort verwendet:
		Es werden die Elemente an jedem Splitter einzeln auf beide Seiten verteilt und dann wird der Algorithmus für beide Seiten wiederholt.
		Das Übernehmen der Splitter in die nächste Iteration ist hier in den ersten beiden Schleifen realisiert, in dem die Splitter am Anfang bzw. ende der beiden Hälften positioniert werden.
		Um diesen Aufwand zu vermeiden ist es auch denkbar, zunächst mit dem letzten Splitter zu starten, damit die Splitter am Anfang des Arrays nicht bewegt werden müssen.
		Oder es kann ganz vermieden werden, wenn auf eine in-place Implementierung verzichtet wird.\\
		Hier ist allerdings ein rekursiver Ansatz gewählt, der von der Mitte zum Rand arbeitet.
		So kann der Sortierprozess für jeden Bucket angestoßen werden, sobald eine Hälfte keine Splitter mehr beinhaltet.\\
		Daraus ergeben sich $n\log_2s$ vergleiche so wie Austausch Operationen, was einer Laufzeitkomplexität von $\Theta(n\log{s})$ entspricht.\footnote{$n$ ist die Anzahl der Elemente und $s$ die Anzahl der Splitter}

	\subsection{Sortieren der Buckets}
		Um den Sortierprozess fertigzustellen ist es noch notwendig, alle Buckets zu sortieren.
		In dieser Implementierung geschieht dies zusammen mit dem verteilen auf die Buckets.
		Zur Art und Weise, wie die Buckets sortiert werden, gibt es allerdings 2 Überlegungen:
		\subsubsection{Original}
			Im Original \autocite{frazer-1970} wird Quicksort verwendet, um die Buckets zu sortieren.
			Der zugrundeliegende Gedanke ist, dass, durch das initiale gleichmäßige verteilen der Elemente, jeder Prozessorkern nun annähernd gleich viele Elemente bearbeiten soll.\\
			Auch wenn im Original Quicksort verwendet wird, so wird dieser Gedanke auch von jeglichem Divide-and-Conquer Algorithmus mit einer durchschnittlichen Laufzeit von annähernd $O(n\log{n})$\footnote{Diese Angabe ist ein Richtwert. Vorausgesetzt es gibt sinnvolle Gründe, wie das Verringern von Vergleichen, kann es sinnvoll sein, diese Laufzeitkomplexität auch im größeren Maße zu überschreiten.} umgesetzt. 
		\subsubsection{Rekursiv}
			Dem entgegen steht die rekursive Implementierung.
			Diese ist auch in \ref{fig:skeletton} umgesetzt.\\
			Hier ist der Vorteil der geringen Anzahl an Vergleichen von Samplesort länger gegeben.
			Als Rekursionsanker dient in der Regel ein Schwellenwert (\textit{threshold}).
			Überschreitet die durchschnittliche Größe eines Buckets diese Zahl, so wird zu einem alternativen Sortieralgorithmus gewechselt.\\
			Hier bietet sich Insertion Sort an, da dieser für kleine Datenmengen optimal ist. \autocite{geeksforgeeks-2021} 
			In vielen Ausführungen ist hier allerdings auch ein Quicksort zu finden.
			Die Entscheidung sollte von der Größe des Schwellenwerts getrieben sein.
